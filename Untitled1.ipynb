{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798c9381-c3e2-41d1-9ff4-b30cbd730fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1What is Ensemble Learning in machine learning? Explain the key idea behind it. \n",
    "#>>Ensemble Learning in machine learning is a technique that combines multiple individual models (often called weak learners or base models) to build a more powerful and accurate predictive model.\n",
    "#Train multiple models on the same (or slightly different) data.\n",
    "#Combine their predictions using a specific strategy (e.g., voting, averaging, or stacking).\n",
    "#The final output is more accurate than most individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4fca98-639e-4088-8ac6-7f8a7cc53811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.What is the difference between Bagging and Boosting?  in para in brief\n",
    "#Bagging (Bootstrap Aggregating) and Boosting are both ensemble learning techniques, but they differ in how they build and combine models.\n",
    "#In Bagging, multiple models (like decision trees) are trained independently on different random subsets of the training data (sampled with replacement). Their predictions are then combined by averaging or voting, which helps reduce variance and prevent overfitting.\n",
    "#In contrast, Boosting builds models sequentially, where each new model focuses on correcting the errors made by the previous ones. The models are combined in a weighted manner, giving more importance to those with better performance. Boosting aims to reduce bias and improve accuracy but can be more sensitive to noisy data compared to Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02777190-8aa2-4e68-bfe5-2d51a7f6053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?\n",
    "#>>Bootstrap sampling is a technique where multiple random samples are drawn with replacement from the original dataset, meaning some data points may appear more than once while others may be left out.\n",
    "#In Bagging methods like Random Forest, bootstrap sampling allows each model (e.g., each decision tree) to train on a slightly different subset of the data. This introduces diversity among the models, reducing the chance that all of them make the same errors. When their predictions are combined (by averaging or voting), this diversity helps to reduce variance and improve the overall accuracy and stability of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc2e3b4-e482-45c5-88b0-7c41fc9d4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?\n",
    "#>>Out-of-Bag (OOB) samples are the data points not included in a particular bootstrap sample when training models in ensemble methods like Random Forest. Since bootstrap sampling is done with replacement, about one-third of the original data is typically left out (not selected) for each tree — these are the OOB samples for that tree.\n",
    "#The OOB score is a way to evaluate the model’s performance without using a separate validation or test set. After training, each tree predicts the output for its own OOB samples, and the combined predictions from all trees are compared to the true values. The proportion of correctly predicted instances (for classification) or the prediction accuracy (for regression) gives the OOB score, which serves as an unbiased estimate of the model’s generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef222105-0d20-43eb-9f46-2b895c15774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5Compare feature importance analysis in a single Decision Tree vs. a Random Forest\n",
    "#>>In a single Decision Tree,feature importance is calculated based on how much each feature reduces impurity (like Gini impurity or entropy) across all the tree’s splits. Features used near the root or in many informative splits tend to have higher importance. However, because a single tree is sensitive to data variations, its feature importance can be unstable and may overfit to the training data.\n",
    "#In contrast, a Random Forest calculates feature importance by averaging the importance scores of each feature across all trees in the forest. This aggregation makes the importance estimates more reliable, stable, and generalizable, since the randomization in data (bootstrap sampling) and feature selection reduces bias toward any specific feature. Thus, Random Forest provides a more robust and accurate measure of which features truly influence the model’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d18c23-ef29-4047-b6b6-26a22090258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Important Features:\n",
      "\n",
      "worst area              0.139357\n",
      "worst concave points    0.132225\n",
      "mean concave points     0.107046\n",
      "worst radius            0.082848\n",
      "worst perimeter         0.080850\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#6  Write a Python program to: ● Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer() ● Train a Random Forest Classifier ● Print the top 5 most important features based on feature importance scores. \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort and print the top 5 features\n",
    "top_features = feature_importances.sort_values(ascending=False).head(5)\n",
    "print(\"Top 5 Most Important Features:\\n\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45a133c-b0ef-431e-b572-b6a2182ea631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Comparison:\n",
      "Single Decision Tree Accuracy: 1.0000\n",
      "Bagging Classifier Accuracy:   1.0000\n"
     ]
    }
   ],
   "source": [
    "#7 Write a Python program to: ● Train a Bagging Classifier using Decision Trees on the Iris dataset ● Evaluate its accuracy and compare with a single Decision Tree \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a single Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Train a Bagging Classifier using Decision Trees as base estimators\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  # Updated parameter name\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bag = bagging.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "# Print the comparison\n",
    "print(\"Accuracy Comparison:\")\n",
    "print(f\"Single Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Bagging Classifier Accuracy:   {bagging_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8a594e-807a-4223-b3fa-a66bebe83bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 5, 'n_estimators': 150}\n",
      "Final Test Accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "#8  Write a Python program to: ● Train a Random Forest Classifier ● Tune hyperparameters max_depth and n_estimators using GridSearchCV ● Print the best parameters and final accuracy \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7, None]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best combination\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b8b5b5-89d2-40c0-a030-b634ef087d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) Comparison:\n",
      "Bagging Regressor MSE:       0.2579\n",
      "Random Forest Regressor MSE: 0.2577\n"
     ]
    }
   ],
   "source": [
    "#9 : Write a Python program to: ● Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset ● Compare their Mean Squared Errors (MSE) \n",
    "# Import required libraries\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Bagging Regressor with Decision Trees as base estimators\n",
    "bagging_reg = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_reg.predict(X_test)\n",
    "mse_bag = mean_squared_error(y_test, y_pred_bag)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_reg.fit(X_train, y_train)\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Print the comparison\n",
    "print(\"Mean Squared Error (MSE) Comparison:\")\n",
    "print(f\"Bagging Regressor MSE:       {mse_bag:.4f}\")\n",
    "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b886d9fc-df59-4ee3-8c51-b5824cbffdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "RandomForestClassifier - ROC-AUC: 0.9957 ± 0.0004\n",
      "RandomForestClassifier - F1-score: 0.9697 ± 0.0021\n",
      "\n",
      "GradientBoostingClassifier - ROC-AUC: 0.9845 ± 0.0011\n",
      "GradientBoostingClassifier - F1-score: 0.9414 ± 0.0052\n",
      "\n",
      "RandomForestClassifier Test Set:\n",
      "ROC-AUC: 0.9419, F1: 0.7902, PR-AUC: 0.8435\n",
      "\n",
      "GradientBoostingClassifier Test Set:\n",
      "ROC-AUC: 0.9183, F1: 0.6751, PR-AUC: 0.7936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10 You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data. You decide to use ensemble techniques to increase model performance. Explain your step-by-step approach to: ● Choose between Bagging or Boosting ● Handle overfitting ● Select base models ● Evaluate performance using cross-validation ● Justify how ensemble learning improves decision-making in this real-world context. \n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load or create dataset\n",
    "# -------------------------\n",
    "# Example synthetic dataset (replace with your real customer data)\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, \n",
    "                           n_redundant=5, n_clusters_per_class=2,\n",
    "                           weights=[0.9, 0.1], flip_y=0.01, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Train-test split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Handle imbalance\n",
    "# -------------------------\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Define models\n",
    "# -------------------------\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Cross-validation\n",
    "# -------------------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    roc_scores = cross_val_score(model, X, y, cv=skf, scoring='roc_auc')\n",
    "    f1_scores = cross_val_score(model, X, y, cv=skf, scoring='f1')\n",
    "    print(f\"{model.__class__.__name__} - ROC-AUC: {roc_scores.mean():.4f} ± {roc_scores.std():.4f}\")\n",
    "    print(f\"{model.__class__.__name__} - F1-score: {f1_scores.mean():.4f} ± {f1_scores.std():.4f}\\n\")\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "evaluate_model(rf_model, X_train_res, y_train_res)\n",
    "evaluate_model(gb_model, X_train_res, y_train_res)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Train final model and evaluate on test set\n",
    "# -------------------------\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "gb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "for model in [rf_model, gb_model]:\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    print(f\"{model.__class__.__name__} Test Set:\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}, F1: {f1:.4f}, PR-AUC: {pr_auc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f932346-1e31-40c8-acf9-dd57f576e34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
